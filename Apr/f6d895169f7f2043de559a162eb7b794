Social media executives risk jail for failing to take down violent extremist content quickly, under controversial laws passed in Australia on Thursday — a “world first” in the wake of the Christchurch mosques massacre. Lawmakers voted overwhelmingly in favour of the laws, which hold firms like Facebook and YouTube — and their executives — responsible for removing “abhorrent material” quickly. The companies face fines approaching billions of dollars — or 10% of global annual turnover — for failing to enact the “expeditious removal” of footage of terrorism, murder and other serious crimes, while executives could face up to three years in jail. Technology companies, policy experts and lawyers pilloried the legislation—which was jammed through parliament in two days and faces an uncertain future beyond elections expected in May. Prime Minister Scott Morrison, who is facing a difficult reelection battle, said: “Big social media companies have a responsibility to take every possible action to ensure their technology products are not exploited by murderous terrorists.” Attorney-General Christian Porter said the legislation was “most likely a world first.” The opposition Labour party expressed serious misgivings but voted in favour of the legislation — in a step that echoed the bipartisan passage of a similarly controversial law forcing technology firms to weaken encryption. With those two reforms, Australia has put itself at the forefront of global efforts to regulate social media giants more closely.
But both measures have been roundly condemned by industry and experts as “knee-jerk” and ill-conceived. It will be up to a jury to decide whether the platforms acted with good speed to take down offending content, raising questions about how the law will be implemented. “No one wants abhorrent content on their websites, and DIGI members work to take this down as quickly as possible,” said Sunita Bose, managing director of the Digital Industry Group, which represents Google, Facebook, Twitter, Amazon and others. <div class="nws-ad-wrapper"><style scoped="true">.nws-ad-wrapper * { -webkit-box-sizing: border-box; box-sizing: border-box; } .nws-ad-wrapper { margin: 30px 0; } .nws-ad-content { border: solid 1px #d8d8d8; overflow: hidden; background: #ffffff !important; } .nws-ad-img { width: 45%; padding-right: 13px; float: left; } @media (min-width: 575px) { .nws-ad-img { width: 22%; } } .nws-ad-details { width: 55%; padding-right: 9px; padding-left: 9px; float: left; } @media (min-width: 575px) { .nws-ad-details { width: 78%; } } .nws-ad-details:hover{ color: #000; } .nws-ad-details h3{ font-size: 100%; margin-top: 10px; } .nws-ad-details p{ color: #000; display: none; font-size: 80%; line-height: 1.5em !important; } @media (min-width: 575px) { .nws-ad-details p{ display: block; } } .nws-ad-img img { width: 100%; height: auto; } .nws-ad-promo { color: #fff; background: #f00; display: inline-block; font-family: droid sans, sans-serif; font-size: 10px; font-weight: 700; text-transform: uppercase; letter-spacing: .02rem; padding: 4px 4px 2px !important; line-height: 1; } .nws-ad-company{ color: #ee2324; font-family: droid sans, sans-serif; font-size: 12px; line-height: 1;} </style><div class="container"><div class="row"><div class="col-xs-12 col-md-12"><a href="${URL}" target="_blank"><div class="nws-ad-content"><div class="nws-ad-img"><img src="${THUMBNAIL}" alt="${TITLE}"></div><div class="nws-ad-details"><div class="nws-ad-promo">Promoted</div><h3>${TITLE}</h3><p>${DESCRIPTION}</p><div class="nws-ad-company">${COMPANY_NAME} | ${DISPLAY_URL}</div></div></div><div style="clear:both;"></div></a></div></div></div></div> “But with the vast volumes of content uploaded to the internet every second, this is a highly complex problem that requires discussion with the technology industry, legal experts, the media and civil society to get the solution right — that didn’t happen this week.” She also warned that the law would encourage companies to “proactively surveil” users and slammed parliament’s “pass it now, change it later” approach. “This is not how legislation should be made in a democracy like Australia.” Technology companies now face the task of developing fail-safe moderation tools capable of quickly detecting offensive material in hundreds of billions of media uploads to their platforms. In the immediate aftermath of the Christchurch shootings, Facebook alone said it had taken down 1.5-million videos of the attack. Current tools like Microsoft’s Content Moderator API “cannot automatically classify an image, let alone a video,” according to Monash University’s Robert Merkel. “Nor can it automatically identify videos similar to another video.” The legislation could be a particular problem for smaller platforms used by the far-right, like 4Chan and 8Chan. The CEO of Australian technology firm Atlassian, Scott Farquhar, warned of a broader economic impact: “The legislation is flawed and will unnecessarily cost jobs and damage our tech industry,” he said on Twitter. News organisations also worry they could face legal action. The Law Council of Australia warned the legislation could have “serious unintended consequences,” like muzzling whistle-blowers and “could also lead to censorship of the media, which would be unacceptable.” The Institute of Public Affairs described the legislation as a “blatant attack on the freedom of the media.” “Throwing media executives in jail will increase costs to taxpayers without improving community safety or addressing concerns about violent content being shared on social media platforms,” said researcher Andrew Bushnell. “Companies and executives may respond to the threat of criminal penalties by erring on the side of censorship.” The laws are expected to be followed by steps toward treating social media giants more like publishers, which would make them legally responsible for any content on their platforms. © Agence France-Presse