[The Mail & Guardian is publishing this article as part of a network of over 300 publications that are sharing journalism on the climate crisis.]  Chances are, if you’re under 25, you’ve grown up using YouTube as a definitive source for everything from news to makeup tutorials to cooking how-tos. A study conducted last year shows that 85% of Americans ages 13 to 17 use YouTube, making it the most popular social platform for teens, and a survey published last month shows that half of teens get their news from the platform. But people searching for accurate information about climate change may end up finding conspiracy theories and climate change denial.
New research shows that an alarming number of of videos hosted on YouTube contain information that contradicts the scientific consensus that humans are causing dangerous climate change — and those videos rack up a huge number of views. Researcher Joachim Allgaier, author of the study published in the journal Frontiers in Communication, said he wanted to look at a little-inspected aspect of the site: the search bar. <div class="nws-ad-wrapper"><style scoped="true">.nws-ad-wrapper * { -webkit-box-sizing: border-box; box-sizing: border-box; } .nws-ad-wrapper { margin: 30px 0; } .nws-ad-content { border: solid 1px #d8d8d8; overflow: hidden; background: #ffffff !important; } .nws-ad-img { width: 45%; padding-right: 13px; float: left; } @media (min-width: 575px) { .nws-ad-img { width: 22%; } } .nws-ad-details { width: 55%; padding-right: 9px; padding-left: 9px; float: left; } @media (min-width: 575px) { .nws-ad-details { width: 78%; } } .nws-ad-details:hover{ color: #000; } .nws-ad-details h3{ font-size: 100%; margin-top: 10px; } .nws-ad-details p{ color: #000; display: none; font-size: 80%; line-height: 1.5em !important; } @media (min-width: 575px) { .nws-ad-details p{ display: block; } } .nws-ad-img img { width: 100%; height: auto; } .nws-ad-promo { color: #fff; background: #f00; display: inline-block; font-family: droid sans, sans-serif; font-size: 10px; font-weight: 700; text-transform: uppercase; letter-spacing: .02rem; padding: 4px 4px 2px !important; line-height: 1; } .nws-ad-company{ color: #ee2324; font-family: droid sans, sans-serif; font-size: 12px; line-height: 1;} </style><div class="container"><div class="row"><div class="col-xs-12 col-md-12"><a href="${URL}" target="_blank"><div class="nws-ad-content"><div class="nws-ad-img"><img src="${THUMBNAIL}" alt="${TITLE}"></div><div class="nws-ad-details"><div class="nws-ad-promo">Promoted</div><h3>${TITLE}</h3><p>${DESCRIPTION}</p><div class="nws-ad-company">${COMPANY_NAME} | ${DISPLAY_URL}</div></div></div><div style="clear:both;"></div></a></div></div></div></div>Studies of YouTube videos, Allgaier said, generally focus on videos with the most views, many of which are from reputable scientific sources with large followings. But the YouTube search algorithm doesn’t just deliver the most-viewed videos related to a topic when a user plugs in a search term. The ranking of search results is based on a patchwork of different factors, including metadata — the terms an uploader attaches to their videos — view counts, specific user preferences, and how viewers interact with the videos. Videos that users watch all the way through, for instance, may be ranked higher than videos many users click but abandon halfway through. For his study, Allgaier said he wanted to take a look at what the average user might see if they logged on to the site to search for climate videos. “If people use YouTube as a search engine and directly type terms that they are interested in, what kind of information will they find?” he said. “Is the content somehow related to the scientific consensus on climate change, or is it something else completely?” Allgaier plugged ten terms into the search bar — including “climate change,” “global warming,” and “geoengineering” — and analysed a total of 200 videos for his study. To make sure YouTube didn’t list videos tailored to his tastes, Allgaier said, he used a tool that anonymised his search results. Of the videos that came up in Allgaier’s search results, more than half presented results at odds with findings from the UN Intergovernmental Panel on Climate Change. These videos weren’t going unnoticed by viewers. The inaccurate videos garnered almost the same number of views as the accurate videos. “I was totally surprised by the sheer scale of this kind of stuff,” Allgaier said. “YouTube to a certain degree has a reputation for being a gold mine for conspiracy theories. But I was really surprised that it actually dominated this [science] content so strongly.” One particularly worrisome topic for Allgaier is geoengineering, the prospect of spraying chemicals into the upper atmosphere to block out some of the sun’s light, cooling the Earth. He estimated that more than 90% of the results for geoengineering contained faulty information, and many were rife with conspiracy theories. “Nothing was really related to the state-of-the-art science or scientists talking about geoengineering,” he said. Searches for geoengineering, in fact, surfaced dozens of videos related to chemtrails. Many conspiracy theorists think the trails of condensation left by aircraft are evidence of a secret government program to use planes to release chemicals to control the weather or the population. As the study notes, chemtrail conspiracy theorists often also deny climate change. “If you were looking for theories and ideas from scientists [when you searched for geoengineering], you would not find scientific ideas at all, but you would only be pointed to the conspiracy content about chemtrails,” he said. “This is really, really harmful for a discussion which we might need to have very soon about these kinds of new ideas and technologies.” It’s not the first time that a big tech company has been found to be propagating bad science. YouTube’s owner, Google, came under fire earlier this month after a Buzzfeed investigation found that its mobile app was promoting climate denier blogs. Google did not respond to a request for comment on this story. And YouTube has received widespread criticism for its seemingly haphazard approach to how it chooses to censor videos with offensive content, hate speech, and misinformation. This summer, Vox journalist Carlos Maza accused the platform of allowing a conservative YouTuber to harass him using homophobic and racial slurs for two years. Other reporting has suggested that promoting controversial content — like hate speech and conspiracy theories — generates more views, meaning users see more ads. Allgaier believes it should be relatively easy to judge which videos are accurate and which aren’t, but he acknowledged that accusations of censorship are still possible even when dealing with straightforward scientific content. “It’s very difficult to come up with a solution for this kind of a problem,” he said. “I would wish, of course, that there would be more factually scientifically correct information on science, technology, research, medicine and so on. But I see that it’s not so easy.” This story originally appeared in Nexus Media. It is republished here as part of the Mail & Guardian’s partnership with Covering Climate Now, a global collaboration of more than 300 news outlets to strengthen coverage of the climate story.